{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.datasets import fetch_datasets\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      8.8        0  \n",
       "1      9.5        0  \n",
       "2     10.1        0  \n",
       "3      9.9        0  \n",
       "4      9.9        0  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the wine quality data for mini-challenge and splitting it into train & test.\n",
    "df =  pd.read_csv(\"../data/Wine_quality.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br /> \n",
    "\n",
    "##  Mini-Challenge - 1\n",
    "***\n",
    "### Print out the distribution percentage of the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad Quality Wine 96.26 % of the dataset\n",
      "Good Quality Wine 3.74 % of the dataset\n"
     ]
    }
   ],
   "source": [
    "# The classes are heavily skewed we need to solve this issue later.\n",
    "print('Bad Quality Wine', round(df['quality'].value_counts()[0]/len(df) * 100,2), '% of the dataset')\n",
    "print('Good Quality Wine', round(df['quality'].value_counts()[1]/len(df) * 100,2), '% of the dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: Notice how imbalanced is our original dataset! Most of the wines sample are Bad Quality. If we use this dataframe as the base for our predictive models and analysis we might get a lot of errors and our algorithms will probably overfit since it will \"assume\" that most of the wines are Bad Quality. But we don't want our model to assume, we want our model to detect patterns that give signs of Good Quality Wine(In other words we need to make sure that bad wines should not be predicted as good ones.)!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br /> \n",
    "\n",
    "##  Mini-Challenge - 2\n",
    "***\n",
    "### Check for class imbalance using a count plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d4f9a4e358>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAD2hJREFUeJzt3X+MZWV9x/H3hwXUpirojtbu0g6p20ZM668NEo2pgRYWrC41YNZU3VCSbRvaqOkvbZNiVRJNafFH1IbK6mIMSKUKGhJDUaqtVZxFqgIhbJXKBsquXUTRQLv67R/3WbnA7Mx91j1zZ5j3K5nMOd/znHu/myz74bnnnOemqpAkaVJHTLsBSdLKYnBIkroYHJKkLgaHJKmLwSFJ6mJwSJK6GBySpC4GhySpi8EhSepy5LQbGMLatWtrdnZ22m1I0oqyc+fO71TVzGLjHpPBMTs7y9zc3LTbkKQVJcl/TTLOj6okSV0MDklSF4NDktTF4JAkdTE4JEldDA5JUheDQ5LUxeCQJHUxOCRJXR6TT44fDi/400un3YKWoZ1/87pptyBNnTMOSVIXg0OS1MXgkCR1MTgkSV0MDklSF4NDktTF4JAkdTE4JEldDA5JUheDQ5LUxeCQJHUxOCRJXQwOSVIXg0OS1MXgkCR1MTgkSV0MDklSF4NDktTF4JAkdTE4JEldDA5JUheDQ5LUxeCQJHUxOCRJXQwOSVIXg0OS1GXw4EiyJslXk3y67R+f5MtJbk/ysSRHt/rj2v6udnx27DXe3Oq3JTlt6J4lSQe3FDOO1wO3ju2/E7ioqjYA9wLntvq5wL1V9UzgojaOJCcAW4BnA5uA9ydZswR9S5LmMWhwJFkPvAz4YNsPcDLw8TZkB3Bm297c9mnHT2njNwOXV9WDVfUtYBdw4pB9S5IObugZx7uAPwN+3PafCny3qva3/d3Aura9DrgToB2/r43/SX2ecyRJS2yw4EjyW8Ceqto5Xp5naC1ybKFzxt9vW5K5JHN79+7t7leSNJkhZxwvBl6R5A7gckYfUb0LOCbJkW3MeuCutr0bOA6gHX8ysG+8Ps85P1FVF1fVxqraODMzc/j/NJIkYMDgqKo3V9X6qppldHH7s1X1O8DngLPasK3AVW376rZPO/7ZqqpW39Luujoe2ADcMFTfkqSFHbn4kMPuz4HLk7wd+CpwSatfAnwkyS5GM40tAFV1c5IrgFuA/cB5VfWjpW9bkgRLFBxVdT1wfdv+JvPcFVVVDwBnH+T8C4ALhutQkjQpnxyXJHUxOCRJXQwOSVIXg0OS1MXgkCR1MTgkSV0MDklSF4NDktTF4JAkdTE4JEldDA5JUheDQ5LUxeCQJHUxOCRJXQwOSVIXg0OS1MXgkCR1MTgkSV0MDklSF4NDktTF4JAkdTE4JEldDA5JUheDQ5LUxeCQJHUxOCRJXQwOSVIXg0OS1MXgkCR1MTgkSV0MDklSF4NDktTF4JAkdTE4JEldDA5JUpfBgiPJ45PckOQ/ktyc5K9b/fgkX05ye5KPJTm61R/X9ne147Njr/XmVr8tyWlD9SxJWtyQM44HgZOr6jnAc4FNSU4C3glcVFUbgHuBc9v4c4F7q+qZwEVtHElOALYAzwY2Ae9PsmbAviVJCxgsOGrk/rZ7VPsp4GTg462+AzizbW9u+7TjpyRJq19eVQ9W1beAXcCJQ/UtSVrYoNc4kqxJchOwB7gW+E/gu1W1vw3ZDaxr2+uAOwHa8fuAp47X5zlHkrTEBg2OqvpRVT0XWM9olvCs+Ya13znIsYPVHybJtiRzSeb27t17qC1LkhaxJHdVVdV3geuBk4BjkhzZDq0H7mrbu4HjANrxJwP7xuvznDP+HhdX1caq2jgzMzPEH0OSxLB3Vc0kOaZtPwH4DeBW4HPAWW3YVuCqtn1126cd/2xVVatvaXddHQ9sAG4Yqm9J0sKOXHzIIXsGsKPdAXUEcEVVfTrJLcDlSd4OfBW4pI2/BPhIkl2MZhpbAKrq5iRXALcA+4HzqupHA/YtSVrAYMFRVV8DnjdP/ZvMc1dUVT0AnH2Q17oAuOBw9yhJ6ueT45KkLgaHJKmLwSFJ6mJwSJK6GBySpC4GhySpy0TBkeS6SWqSpMe+BZ/jSPJ44GeAtUmO5aF1o54E/PzAvUmSlqHFHgD8PeANjEJiJw8Fx/eA9w3YlyRpmVowOKrq3cC7k/xRVb13iXqSJC1jEy05UlXvTfIiYHb8nKq6dKC+JEnL1ETBkeQjwC8BNwEHFhgswOCQpFVm0kUONwIntGXOJUmr2KTPcXwD+LkhG5EkrQyTzjjWArckuQF48ECxql4xSFeSpGVr0uB4y5BNSJJWjknvqvqXoRuRJK0Mk95V9X1Gd1EBHA0cBfygqp40VGOSpOVp0hnHE8f3k5zJPF//Kkl67Duk1XGr6pPAyYe5F0nSCjDpR1WvHNs9gtFzHT7TIUmr0KR3Vb18bHs/cAew+bB3I0la9ia9xnHO0I1IklaGSb/IaX2STyTZk+SeJFcmWT90c5Kk5WfSi+MfAq5m9L0c64BPtZokaZWZNDhmqupDVbW//XwYmBmwL0nSMjVpcHwnyWuSrGk/rwH+Z8jGJEnL06TB8bvAq4D/Bu4GzgK8YC5Jq9Ckt+O+DdhaVfcCJHkKcCGjQJEkrSKTzjh+7UBoAFTVPuB5w7QkSVrOJg2OI5Ice2CnzTgmna1Ikh5DJv3H/2+BLyb5OKOlRl4FXDBYV5KkZWvSJ8cvTTLHaGHDAK+sqlsG7UyStCxN/HFTCwrDQpJWuUNaVl2StHoNFhxJjkvyuSS3Jrk5yetb/SlJrk1ye/t9bKsnyXuS7ErytSTPH3utrW387Um2DtWzJGlxQ8449gN/XFXPAk4CzktyAvAm4Lqq2gBc1/YBTgc2tJ9twAfgJ3dwnQ+8kNG3Dp4/foeXJGlpDRYcVXV3Vd3Ytr8P3MpogcTNwI42bAdwZtveDFxaI18CjknyDOA04Nqq2teeJbkW2DRU35KkhS3JNY4ks4weGPwy8PSquhtG4QI8rQ1bB9w5dtruVjtYXZI0BYMHR5KfBa4E3lBV31to6Dy1WqD+yPfZlmQuydzevXsPrVlJ0qIGDY4kRzEKjY9W1T+18j3tIyja7z2tvhs4buz09cBdC9QfpqourqqNVbVxZsYV3yVpKEPeVRXgEuDWqvq7sUNXAwfujNoKXDVWf127u+ok4L72UdZngFOTHNsuip/aapKkKRhyvakXA68Fvp7kplb7C+AdwBVJzgW+DZzdjl0DnAHsAn5IW7a9qvYleRvwlTburW2RRUnSFAwWHFX1r8x/fQLglHnGF3DeQV5rO7D98HUnSTpUPjkuSepicEiSuhgckqQuBockqYvBIUnqYnBIkroYHJKkLgaHJKmLwSFJ6mJwSJK6GBySpC4GhySpi8EhSepicEiSuhgckqQuBockqYvBIUnqYnBIkroYHJKkLgaHJKmLwSFJ6mJwSJK6GBySpC4GhySpi8EhSepicEiSuhgckqQuBockqYvBIUnqYnBIkroYHJKkLgaHJKmLwSFJ6mJwSJK6GBySpC6DBUeS7Un2JPnGWO0pSa5Ncnv7fWyrJ8l7kuxK8rUkzx87Z2sbf3uSrUP1K0mazJAzjg8Dmx5RexNwXVVtAK5r+wCnAxvazzbgAzAKGuB84IXAicD5B8JGkjQdgwVHVX0e2PeI8mZgR9veAZw5Vr+0Rr4EHJPkGcBpwLVVta+q7gWu5dFhJElaQkt9jePpVXU3QPv9tFZfB9w5Nm53qx2sLkmakuVycTzz1GqB+qNfINmWZC7J3N69ew9rc5Kkhyx1cNzTPoKi/d7T6ruB48bGrQfuWqD+KFV1cVVtrKqNMzMzh71xSdLIUgfH1cCBO6O2AleN1V/X7q46CbivfZT1GeDUJMe2i+KntpokaUqOHOqFk1wGvBRYm2Q3o7uj3gFckeRc4NvA2W34NcAZwC7gh8A5AFW1L8nbgK+0cW+tqkdecJckLaHBgqOqXn2QQ6fMM7aA8w7yOtuB7YexNUnST2G5XByXJK0QBockqYvBIUnqYnBIkroYHJKkLgaHJKmLwSFJ6mJwSJK6GBySpC4GhySpi8EhSepicEiSuhgckqQuBockqYvBIUnqYnBIkroYHJKkLgaHJKmLwSFJ6mJwSJK6GBySpC4GhySpi8EhSepicEiSuhgckqQuBockqYvBIUnqYnBIkroYHJKkLgaHJKmLwSFJ6nLktBuQ1Ofbb/3VabegZegX/urrS/ZezjgkSV0MDklSF4NDktRlxQRHkk1JbkuyK8mbpt2PJK1WKyI4kqwB3gecDpwAvDrJCdPtSpJWpxURHMCJwK6q+mZV/S9wObB5yj1J0qq0UoJjHXDn2P7uVpMkLbGV8hxH5qnVwwYk24Btbff+JLcN3tXqsRb4zrSbWA5y4dZpt6CH8+/mAefP989kt1+cZNBKCY7dwHFj++uBu8YHVNXFwMVL2dRqkWSuqjZOuw/pkfy7OR0r5aOqrwAbkhyf5GhgC3D1lHuSpFVpRcw4qmp/kj8EPgOsAbZX1c1TbkuSVqUVERwAVXUNcM20+1il/AhQy5V/N6cgVbX4KEmSmpVyjUOStEwYHFqQS71oOUqyPcmeJN+Ydi+rkcGhg3KpFy1jHwY2TbuJ1crg0EJc6kXLUlV9Htg37T5WK4NDC3GpF0mPYnBoIYsu9SJp9TE4tJBFl3qRtPoYHFqIS71IehSDQwdVVfuBA0u93Apc4VIvWg6SXAb8O/ArSXYnOXfaPa0mPjkuSerijEOS1MXgkCR1MTgkSV0MDklSF4NDktTF4JCmIMnsgZVdk2xM8p62/dIkL5pud9LCVsw3AEqPVVU1B8y13ZcC9wNfnFpD0iKccUidkvxl+46Sf05yWZI/SXJ9ko3t+Nokd7Tt2SRfSHJj+3nUbKLNMj6dZBb4feCNSW5K8pIk30pyVBv3pCR3HNiXpsUZh9QhyQsYLb3yPEb//dwI7FzglD3Ab1bVA0k2AJcBG+cbWFV3JPl74P6qurC93/XAy4BPtve9sqr+7zD9caRD4oxD6vMS4BNV9cOq+h6Lr911FPAPSb4O/COjL8Tq8UHgnLZ9DvChzvOlw84Zh9RvvnV69vPQ/4g9fqz+RuAe4Dnt+ANdb1T1b+3jrl8H1lSVX5WqqXPGIfX5PPDbSZ6Q5InAy1v9DuAFbfussfFPBu6uqh8DrwXWLPL63wee+IjapYw+4nK2oWXB4JA6VNWNwMeAm4ArgS+0QxcCf5Dki8DasVPeD2xN8iXgl4EfLPIWn2IUTDcleUmrfRQ4llF4SFPn6rjSTyHJWxi7mD3Qe5wFbK6q1w71HlIPr3FIy1iS9wKnA2dMuxfpAGcckqQuXuOQJHUxOCRJXQwOSVIXg0OS1MXgkCR1MTgkSV3+H/rAodc9fjinAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot('quality', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distributions: By seeing the distributions we can have an idea how skewed are these features. There are techniques that can help the distributions be less skewed which will be implemented in this notebook.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br /> \n",
    "\n",
    "##  Mini-Challenge - 3\n",
    "***\n",
    "* Store the independent attributes in the X variable and dependent variable(`quality`) in y and split X and y into X_train,X_test,y_train,y_test with `random_state=2`\n",
    "* Fit a Random forest classifier model with random_state=42 on the imbalanced data. Find out the f1-score, precision score, recall score, roc-auc score, confusion matrix and accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:   0.9640816326530612\n",
      "Recall:           0.13953488372093023\n",
      "Precision Score:  0.46153846153846156\n",
      "F1 Score:         0.21428571428571427\n",
      "Confusion Matrix: \n",
      " [[1175    7]\n",
      " [  37    6]]\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('quality', axis=1)\n",
    "y = df['quality']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,random_state=2)\n",
    "rf_classifier_bal = RandomForestClassifier(random_state=42)\n",
    "rf_classifier_bal.fit(X_train,y_train)\n",
    "y_pred = rf_classifier_bal.predict(X_test)\n",
    "\n",
    "accuracy = rf_classifier_bal.score(X_test,y_test)\n",
    "print(\"Accuracy Score:  \",accuracy)\n",
    "\n",
    "recall = recall_score(y_test,y_pred)\n",
    "print(\"Recall:          \",recall)\n",
    "\n",
    "precision = precision_score(y_test,y_pred)\n",
    "print('Precision Score: ',precision)\n",
    "\n",
    "f1 = f1_score(y_test,y_pred)\n",
    "print(\"F1 Score:        \",f1)\n",
    "\n",
    "confusion_mat =confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix: \\n\",confusion_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br /> \n",
    "\n",
    "##  Mini-Challenge - 4\n",
    "***\n",
    "###  In above challenge we got an accuracy of 0.96 but we can see our recall is 0.13 which is very less. Lets try to improve the recall/F1 score. \n",
    "**Let's now try to see if random undersampling will improve the performance of our ML model**\n",
    "* Implement undersampling using random_under_sampler of imblearn with random_state =42.\n",
    "* And then, Fit a random forest classifier model with random_state=42 on the balanced data. Find out the f1-score, precision score, recall score, roc-auc score, confusion matrix and accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:   0.7828571428571428\n",
      "Recall:           0.7441860465116279\n",
      "Precision Score:  0.11149825783972125\n",
      "F1 Score:         0.19393939393939394\n",
      "Confusion Matrix: \n",
      " [[927 255]\n",
      " [ 11  32]]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Code starts here\n",
    "rus = RandomUnderSampler(random_state =42)\n",
    "X_sample2 ,y_sample2= rus.fit_sample(X_train,y_train)\n",
    "\n",
    "# implement logistic regression\n",
    "model_rus = RandomForestClassifier(random_state=42)\n",
    "model_rus.fit(X_sample2,y_sample2)\n",
    "y_pred = model_rus.predict(X_test)\n",
    "\n",
    "accuracy_rus = model_rus.score(X_test,y_test)\n",
    "print(\"Accuracy Score:  \",accuracy_rus)\n",
    "\n",
    "recall_rus = recall_score(y_test,y_pred)\n",
    "print(\"Recall:          \",recall_rus)\n",
    "\n",
    "precision_rus = precision_score(y_test,y_pred)\n",
    "print('Precision Score: ',precision_rus)\n",
    "\n",
    "f1_rus = f1_score(y_test,y_pred)\n",
    "print(\"F1 Score:        \",f1_rus)\n",
    "\n",
    "confusion_mat_rus =confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix: \\n\",confusion_mat_rus)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br /> \n",
    "\n",
    "##  Mini-Challenge - 5\n",
    "***\n",
    "### Oversampling has an advantage over undersampling in the form of no information loss. Let's see if our Random Forest Classifier model works better after random oversampling\n",
    "* Implement oversampling using RandomOverSampler of imblearn with random_state=4\n",
    "* And then, Fit a Random forest classifier model with random_state=42 on the balanced data. Find out the f1-score, precision score, recall score, roc-auc score, confusion matrix and accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:   0.9657142857142857\n",
      "Recall:           0.13953488372093023\n",
      "Precision Score:  0.5454545454545454\n",
      "F1 Score:         0.22222222222222218\n",
      "Confusion Matrix: \n",
      " [[1177    5]\n",
      " [  37    6]]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Code starts here\n",
    "ros = RandomOverSampler(random_state = 4)\n",
    "\n",
    "X_sample5 , y_sample5 = ros.fit_sample(X_train,y_train)\n",
    "\n",
    "model_ros = RandomForestClassifier(random_state = 42)\n",
    "model_ros.fit(X_sample5,y_sample5)\n",
    "y_pred = model_ros.predict(X_test)\n",
    "\n",
    "accuracy_ros = model_ros.score(X_test,y_test)\n",
    "print(\"Accuracy Score:  \",accuracy_ros)\n",
    "\n",
    "recall_ros = recall_score(y_test,y_pred)\n",
    "print(\"Recall:          \",recall_ros)\n",
    "\n",
    "precision_ros = precision_score(y_test,y_pred)\n",
    "print('Precision Score: ',precision_ros)\n",
    "\n",
    "f1_ros = f1_score(y_test,y_pred)\n",
    "print(\"F1 Score:        \",f1_ros)\n",
    "\n",
    "confusion_mat_ros =confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix: \\n\",confusion_mat_ros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/quiz.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br /> \n",
    "\n",
    "### Challenges in Machine Learning\n",
    "***\n",
    "Q1. Cluster sampling, stratified sampling and systematic sampling are types of\n",
    "```python\n",
    "A. direct sampling\n",
    "B. indirect sampling\n",
    "C. random sampling\n",
    "D. non random sampling\n",
    "Ans:- C\n",
    "```\n",
    "Q2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
