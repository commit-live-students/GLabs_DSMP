{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>20 Newsgroups data</center>\n",
    "\n",
    "The 20 Newsgroups data set is a collection of approximately 20,000 newsgroup documents, partitioned (nearly) evenly across 20 different newsgroups. To the best of my knowledge, it was originally collected by Ken Lang, probably for his Newsweeder: Learning to filter netnews paper, though he does not explicitly mention this collection. The 20 newsgroups collection has become a popular data set for experiments in text applications of machine learning techniques, such as text classification and text clustering.\n",
    "\n",
    "\n",
    "\n",
    "## About the dataset\n",
    "The data is organized into 20 different newsgroups, each corresponding to a different topic. Some of the newsgroups are very closely related to each other (e.g. comp.sys.ibm.pc.hardware / comp.sys.mac.hardware), while others are highly unrelated (e.g misc.forsale / soc.religion.christian). Here is a list of the 20 newsgroups, partitioned (more or less) according to subject matter:\n",
    "\n",
    "```python\n",
    "comp.graphics\n",
    "comp.os.ms-windows.misc\n",
    "comp.sys.ibm.pc.hardware\n",
    "comp.sys.mac.hardware\n",
    "comp.windows.x\t\n",
    "rec.autos\n",
    "rec.motorcycles\n",
    "rec.sport.baseball\n",
    "rec.sport.hockey\n",
    "sci.crypt\n",
    "sci.electronics\n",
    "sci.med\n",
    "sci.space\n",
    "misc.forsale\t\n",
    "talk.politics.misc\n",
    "talk.politics.guns\n",
    "talk.politics.mideast\n",
    "talk.religion.misc\n",
    "alt.atheism\n",
    "soc.religion.christian\n",
    "```\n",
    "\n",
    "The dataset used in this example is the 20 newsgroups dataset which will be automatically downloaded and then cached and reused for the document classification example.\n",
    "\n",
    "You can adjust the number of categories by giving their names to the dataset loader or setting them to None to get the 20 of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from pprint import pprint\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score , f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    }
   ],
   "source": [
    "df = fetch_20newsgroups(subset='train')\n",
    "pprint(list(df.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Create a list of 4 newsgroup and fetch it using function `fetch_20newsgroups` for both train and test data.\n",
    "***\n",
    "### Instructions\n",
    "\n",
    "- Create a list of 4 newsgroup i.e `'alt.atheism'`, `'talk.religion.misc'`, `'comp.graphics'`, `'sci.space'` and save it as `categories`\n",
    "- Fetch 4 newsgroup using function `fetch_20newsgroups` with parameters as `subset='train'`,`categories=categories` and store it in `newsgroups_train` variable. Similarly do it for test and store in `newsgroups_test`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Use TfidfVectorizer on train data and find out the Number of Non-Zero components per sample.\n",
    "***\n",
    "### Instructions\n",
    " - Initialise a `TfidfVectorizer()` object and save it as `vectorizer`\n",
    " - Apply the \"fit_transform()\" method of `vectorizer` on `newsgroups_train.data` and store the result in `vectors`\n",
    " - Print the distribution count of the `vectors`\n",
    " - Find out the Number of Non-Zero components per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Use TfidfVectorizer on test data and apply Naive Bayes model and calculate f1_score.\n",
    "***\n",
    "### Instructions\n",
    "- Apply the `transform()` method  on `newsgroups_test.data` and store the result in `vectors_test`\n",
    "- Initialise a naive bayes model with `MultinomialNB()` having parameter as `alpha=.01` and save it to a variable called `clf`\n",
    "- Apply the `fit()` method of `clf` on `vectors` and `newsgroups_train.target`\n",
    "- Predict on test data i.e `vectors_test` and save it as `pred`\n",
    "- Find out the f1 score between `newsgroups_test.target` and `pred` using the `f1_score` method also pass parameter as `average = 'macro'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Print the top 20 news category and top 20 words for every news category.\n",
    "***\n",
    "As we see that Multinomial Naive Bayes gets a higher F-score of 0.88. You might be thinking what’s going on inside this classifier?\n",
    "\n",
    "Let’s take a look at what the most informative features are:\n",
    "- Create a function `show_top20` with 3 parameters as `classifier`, `vectorizer`, `categories`\n",
    "- Get the feature names using `get_feature_names()` attribute of `vectorizer` and convert it into array and save it as `feature_names`.\n",
    "- Start a `for` loop to iterate over both the index and value of `categories` using `enumerate()` function\n",
    "- Inside the for loop, sort the top 20 coefficient using `argsort()` function of numpy by passing parameter as `classifier.coef_[i][-20]` and save it as in variable `top20`\n",
    "- Print out the corresponding value (`categories` i.e. news category) and top 20 words for every news category\n",
    "- And then call the function as `show_top20(clf, vectorizer, newsgroups_train.target_names)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
